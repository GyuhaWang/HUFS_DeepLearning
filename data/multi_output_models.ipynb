{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/38/d2/3e8c13ffc37ca5ebc6f382b242b44acb43eb489042e1728407ac3904e72f/opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\rui\\.conda\\envs\\hufsg\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/38.1 MB 2.0 MB/s eta 0:00:20\n",
      "   --- ------------------------------------ 3.2/38.1 MB 41.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 8.4/38.1 MB 67.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 13.5/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 18.6/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 21.2/38.1 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 23.1/38.1 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 24.2/38.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 28.8/38.1 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.0/38.1 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.1/38.1 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 65.5 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-WM7nvf41Xz",
    "outputId": "243fd2d1-0b49-44e1-b16d-37c1e59f0743"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "#from google.colab import drive\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#!drive unmount\n",
    "#!drive mount '/content/drive', force_remount=True\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_group(data,category):\n",
    "    label_dict = {data: i for i, data in enumerate(category)}\n",
    "    #print(label_dict)\n",
    "    data_indices = [label_dict[str(data)]]\n",
    "    #print(label_dict)\n",
    "    one_hot = torch.nn.functional.one_hot(torch.tensor(data_indices), len(category))\n",
    "    #print(one_hot)\n",
    "    return one_hot\n",
    "    \n",
    "def combine_one_hot_labels(*vectors):\n",
    "    return torch.cat(vectors, dim=0)\n",
    "\n",
    "def add_extension(img_path):\n",
    "    if not img_path.endswith(\".jpg\"):\n",
    "        img_path += \".jpg\"\n",
    "    return img_path\n",
    "\n",
    "def one_hot_encode_label(folder_path,file_name,label_name):\n",
    "    # 라벨 파일 읽기\n",
    "    file_path = folder_path+\"/\"+file_name\n",
    "    with open(file_path, 'r') as file:\n",
    "        label_data = json.load(file)\n",
    "\n",
    "    if label_name == \"image\":\n",
    "        img_path = label_data[\"imgName\"]\n",
    "        img_path_with_extension = add_extension(img_path)\n",
    "        return img_path_with_extension\n",
    "    \n",
    "    era = str(label_data[\"era\"])\n",
    "    era_category = ['1950','1960','1970','1980','1990','2000','2010','2019']\n",
    "    \n",
    "    style = label_data[\"style\"]\n",
    "    style_category = [\"ivy\",\"feminine\",\"classic\",\"mods\",\"minimal\",\"popart\",\"space\",\"hippie\",\"disco\",\"military\",\"punk\",\"bold\",\"powersuit\",\"bodyconscious\",\"hiphop\",\"kitsch\",\"lingerie\",\"grunge\",\"metrosexual\",\"cityglam\",\"oriental\",\"ecology\",\"sportivecasual\",\"athleisure\",\"lounge\",\"normcore\",\"genderless\"]\n",
    "    \n",
    "    gender = label_data[\"gender\"]\n",
    "    gender_category = ['M','W']\n",
    "    \n",
    "    survey_data = label_data[\"survey\"]\n",
    "    q1 = survey_data[\"Q1\"]\n",
    "    q1_category = [\"1\",\"2\",\"3\",\"4\"]\n",
    "    q2 = survey_data[\"Q2\"] # 데이터가 여러개임\n",
    "    q2_category = [\"1\",\"2\",\"3\"]\n",
    "    q3 = survey_data[\"Q3\"] # 데이터가 여러개임\n",
    "    q3_category = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"]\n",
    "    q411 = survey_data[\"Q411\"]\n",
    "    q411_category = [\"1\",\"2\",\"3\"]\n",
    "    q412 = survey_data[\"Q412\"]\n",
    "    q412_category = [\"1\",\"2\"]\n",
    "    q413 = survey_data[\"Q413\"]\n",
    "    q413_category = [\"1\",\"2\"]\n",
    "    q414 = survey_data[\"Q414\"]\n",
    "    q414_category = [\"1\",\"2\"]\n",
    "    q42xx_category = [\"0\",\"1\"]\n",
    "    q5 = survey_data[\"Q5\"]\n",
    "    q5_category = [\"1\",\"2\"]\n",
    "\n",
    "    one_hot_result = \"\"\n",
    "\n",
    "    #'''\n",
    "    if label_name == \"era\":\n",
    "        one_hot_result = one_hot_group(era, era_category)\n",
    "    elif label_name == \"style\":\n",
    "        one_hot_result = one_hot_group(style, style_category)\n",
    "    elif label_name == \"gender\":\n",
    "        one_hot_result = one_hot_group(gender, gender_category)\n",
    "    elif label_name == \"q1\":\n",
    "        one_hot_result = one_hot_group(q1,q1_category)\n",
    "    elif label_name == \"q2\":\n",
    "        one_hot_result = one_hot_group(q2,q2_category)\n",
    "    elif label_name == \"q3\":\n",
    "        one_hot_result = one_hot_group(q3,q3_category)\n",
    "    elif label_name == \"q411\":\n",
    "        one_hot_result = one_hot_group(q411,q411_category)\n",
    "    elif label_name == \"q412\":\n",
    "        one_hot_result = one_hot_group(q412,q412_category)\n",
    "    elif label_name == \"q413\":\n",
    "        one_hot_result = one_hot_group(q413,q413_category)\n",
    "    elif label_name == \"q414\":\n",
    "        one_hot_result = one_hot_group(q414,q414_category)\n",
    "    #'''\n",
    "    for i in range(0, 16):\n",
    "        key = f\"Q{4201+i}\"\n",
    "        if label_name == f\"q{4201+i}\":\n",
    "            one_hot_result = one_hot_group(survey_data[key],q42xx_category)\n",
    "            break\n",
    "    '''\n",
    "    combined_label = combine_one_hot_vectors(\n",
    "    era_one_hot, style_one_hot, gender_one_hot,\n",
    "    q1_one_hot, \n",
    "        #q2_one_hot, q3_one_hot,\n",
    "    q411_one_hot, q412_one_hot, q413_one_hot, q414_one_hot, *q42xx_one_hot\n",
    "    )\n",
    "    print(combined_label)\n",
    "    print(combined_label.shape)\n",
    "    '''\n",
    "    \n",
    "    return one_hot_result\n",
    "\n",
    "def label_one_hot(image_path,label_path,label_name):\n",
    "    label_list = os.listdir(label_path)\n",
    "    temp = []\n",
    "    for file_name in label_list:\n",
    "        image_name = one_hot_encode_label(label_path,file_name,\"image\")\n",
    "        label = []\n",
    "        for labels in label_name:\n",
    "            label.extend(one_hot_encode_label(label_path,file_name,labels))\n",
    "        image = image_path +'/'+image_name\n",
    "        data = (image,label)\n",
    "        temp.append(data)\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Training image 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_training_image)\\nprint(\"Training label 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_training_label)\\nprint(\"Vaildation image 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_validation_image)\\nprint(\"Vaildation label 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_validation_label)\\n#'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_subfolder_names(folder_path):\n",
    "    subfolders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
    "    return subfolders\n",
    "\n",
    "#'''\n",
    "folder_path_training_image = 'data/Training/data'\n",
    "folder_path_validation_image = 'data/Validation/data'\n",
    "folder_path_training_label = 'data/Training/label'\n",
    "folder_path_validation_label = 'data/Validation/label'\n",
    "subfolder_names_training_image = get_subfolder_names(folder_path_training_image)\n",
    "subfolder_names_validation_image = get_subfolder_names(folder_path_validation_image)\n",
    "subfolder_names_training_label = get_subfolder_names(folder_path_training_label)\n",
    "subfolder_names_validation_label = get_subfolder_names(folder_path_validation_label)\n",
    "#'''\n",
    "'''\n",
    "print(\"Training image 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_training_image)\n",
    "print(\"Training label 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_training_label)\n",
    "print(\"Vaildation image 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_validation_image)\n",
    "print(\"Vaildation label 폴더 안에 있는 모든 서브폴더명:\", subfolder_names_validation_label)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data 'TS_man_1950' is OK\n",
      "Training Data 'TS_man_1960' is OK\n",
      "Training Data 'TS_man_1970' is OK\n",
      "Training Data 'TS_man_1980' is OK\n",
      "Training Data 'TS_man_1990' is OK\n",
      "Training Data 'TS_man_2000' is OK\n",
      "Training Data 'TS_man_2010' is OK\n",
      "Training Data 'TS_man_2019' is OK\n",
      "Training Data 'TS_woman_1950' is OK\n",
      "Training Data 'TS_woman_1960' is OK\n",
      "Training Data 'TS_woman_1970' is OK\n",
      "Training Data 'TS_woman_1980' is OK\n",
      "Training Data 'TS_woman_1990' is OK\n",
      "Training Data 'TS_woman_2000' is OK\n",
      "Training Data 'TS_woman_2010' is OK\n",
      "Training Data 'TS_woman_2019' is OK\n",
      "Validation Data 'VS_man_1950' is OK\n",
      "Validation Data 'VS_man_1960' is OK\n",
      "Validation Data 'VS_man_1970' is OK\n",
      "Validation Data 'VS_man_1980' is OK\n",
      "Validation Data 'VS_man_1990' is OK\n",
      "Validation Data 'VS_man_2000' is OK\n",
      "Validation Data 'VS_man_2010' is OK\n",
      "Validation Data 'VS_man_2019' is OK\n",
      "Validation Data 'VS_woman_1950' is OK\n",
      "Validation Data 'VS_woman_1960' is OK\n",
      "Validation Data 'VS_woman_1970' is OK\n",
      "Validation Data 'VS_woman_1980' is OK\n",
      "Validation Data 'VS_woman_1990' is OK\n",
      "Validation Data 'VS_woman_2000' is OK\n",
      "Validation Data 'VS_woman_2010' is OK\n",
      "Validation Data 'VS_woman_2019' is OK\n"
     ]
    }
   ],
   "source": [
    "label_list = [\"era\",\"style\",\"gender\",\"q1\",\"q2\",\"q3\",\"q411\",\"q412\",\"q413\",\"q414\",\"q4201\",\"q4202\",\"q4203\",\"q4204\",\"q4205\",\"q4206\",\"q4207\",\"q4208\",\"q4209\",\"q4210\",\"q4211\",\"q4212\",\"q4213\",\"q4214\",\"q4215\",\"q4216\",\"q5\"]\n",
    "train_data = []\n",
    "validation_data =[]\n",
    "#label_list = [\"style\",\"gender\",\"q1\"]\n",
    "#'''\n",
    "for image_path, label_path in zip(subfolder_names_training_image,subfolder_names_training_label):\n",
    "    train_data.extend(label_one_hot(folder_path_training_image + '/' + image_path , folder_path_training_label +'/'+ label_path,label_list))\n",
    "    print(f\"Training Data '{image_path}' is OK\")\n",
    "    #print(folder_path_training_image + '/' + image_path , folder_path_training_label +'/'+ label_path)\n",
    "#'''\n",
    "#'''\n",
    "for image_path, label_path in zip(subfolder_names_validation_image,subfolder_names_validation_label):\n",
    "    validation_data.extend(label_one_hot(folder_path_validation_image + '/' + image_path , folder_path_validation_label +'/'+ label_path,label_list))\n",
    "    print(f\"Validation Data '{image_path}' is OK\")\n",
    "    #print(folder_path_vaildation+'/'+ label_path)\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/Training/data/TS_man_1950/T_00001_50_ivy_M.jpg', [tensor([1, 0, 0, 0, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0]), tensor([1, 0]), tensor([0, 0, 1, 0]), tensor([1, 0, 0]), tensor([0, 0, 0, 0, 1, 0, 0, 0]), tensor([0, 1, 0]), tensor([0, 1]), tensor([0, 1]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([0, 1]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0]), tensor([1, 0])])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path error check\n",
    "for index, (image_path, _) in enumerate(train_data):\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error at index {index}: File not found - {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2개\n",
    "class facedataset(Dataset):\n",
    "    def __init__(self, data, train=True, test=False, transform=None):\n",
    "        self.transform = transform\n",
    "\n",
    "        if test:\n",
    "            self.images = [img for img, labels in data]\n",
    "            self.labels = [labels for img, labels in data]\n",
    "            return\n",
    "\n",
    "        num_samples = len(data)\n",
    "        num_test_samples = int(0.2 * num_samples)\n",
    "        num_train_samples = num_samples - num_test_samples\n",
    "\n",
    "        train_files, test_files = torch.utils.data.random_split(data, [num_train_samples, num_test_samples])\n",
    "\n",
    "        if train:\n",
    "            self.images = [img for img, labels in train_files]\n",
    "            self.labels = [labels for img, labels in train_files]\n",
    "        else:\n",
    "            self.images = [img for img, labels in test_files]\n",
    "            self.labels = [labels for img, labels in test_files]\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        labels = self.labels[idx]\n",
    "        return img, *labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "yB-Xh6fHphIj"
   },
   "outputs": [],
   "source": [
    "batch_size =32\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "     transforms.Resize(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = facedataset(train_data, train= True, transform= transform)\n",
    "validation_dataset =facedataset(train_data, train= False, transform= transform)\n",
    "test_dataset  = facedataset(validation_data, test= True,transform= transform)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_data_loader = DataLoader(validation_dataset,batch_size=batch_size,)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2131\n",
      "533\n",
      "417\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_loader))\n",
    "print(len(validation_data_loader))\n",
    "print(len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 27, 2, 4, 3, 8, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rui\\.conda\\envs\\hufsG\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "label_classes = []\n",
    "data_ex = next(iter(validation_dataset))\n",
    "for i in range(1,len(data_ex)):\n",
    "    labelSize = data_ex[i].size()\n",
    "    label_classes.append(labelSize.numel())\n",
    "print(label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\rui\\.conda\\envs\\hufsg\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel(nn.Module):\n",
    "    def __init__(self, label_classes):\n",
    "        super(MultiOutputModel, self).__init__()\n",
    "        \n",
    "        vgg16_model = models.vgg16(pretrained=True)\n",
    "        for param in vgg16_model.parameters():\n",
    "            param.requires_grad = False;\n",
    "            \n",
    "        self.features = vgg16_model.features\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "            \n",
    "        classifiers = []\n",
    "        for label_class in label_classes:\n",
    "            classifiers.append(nn.Sequential(\n",
    "                nn.Linear(25088, label_class),\n",
    "            ))\n",
    "\n",
    "        self.classifiers = nn.ModuleList(classifiers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        outputs = [classifier(x) for classifier in self.classifiers]\n",
    "\n",
    "        return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "          Flatten-32                [-1, 25088]               0\n",
      "           Linear-33                    [-1, 8]         200,712\n",
      "           Linear-34                   [-1, 27]         677,403\n",
      "           Linear-35                    [-1, 2]          50,178\n",
      "           Linear-36                    [-1, 4]         100,356\n",
      "           Linear-37                    [-1, 3]          75,267\n",
      "           Linear-38                    [-1, 8]         200,712\n",
      "           Linear-39                    [-1, 3]          75,267\n",
      "           Linear-40                    [-1, 2]          50,178\n",
      "           Linear-41                    [-1, 2]          50,178\n",
      "           Linear-42                    [-1, 2]          50,178\n",
      "           Linear-43                    [-1, 2]          50,178\n",
      "           Linear-44                    [-1, 2]          50,178\n",
      "           Linear-45                    [-1, 2]          50,178\n",
      "           Linear-46                    [-1, 2]          50,178\n",
      "           Linear-47                    [-1, 2]          50,178\n",
      "           Linear-48                    [-1, 2]          50,178\n",
      "           Linear-49                    [-1, 2]          50,178\n",
      "           Linear-50                    [-1, 2]          50,178\n",
      "           Linear-51                    [-1, 2]          50,178\n",
      "           Linear-52                    [-1, 2]          50,178\n",
      "           Linear-53                    [-1, 2]          50,178\n",
      "           Linear-54                    [-1, 2]          50,178\n",
      "           Linear-55                    [-1, 2]          50,178\n",
      "           Linear-56                    [-1, 2]          50,178\n",
      "           Linear-57                    [-1, 2]          50,178\n",
      "           Linear-58                    [-1, 2]          50,178\n",
      "================================================================\n",
      "Total params: 17,047,965\n",
      "Trainable params: 2,333,277\n",
      "Non-trainable params: 14,714,688\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.59\n",
      "Params size (MB): 65.03\n",
      "Estimated Total Size (MB): 284.19\n",
      "----------------------------------------------------------------\n",
      "MultiOutputModel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifiers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=8, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=27, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=2, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4, bias=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=3, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=8, bias=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=3, bias=True)\n",
      "    )\n",
      "    (7-25): 19 x Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "label_classes = [8, 27, 2, 4, 3, 8, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
    "'''\n",
    "data_ex = next(iter(validation_dataset))\n",
    "for i in range(1,len(data_ex)):\n",
    "    labelSize = data_ex[i].size()\n",
    "    label_classes.append(labelSize.numel())\n",
    "print(label_classes)\n",
    "'''\n",
    "model = MultiOutputModel(label_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "M614Xmznpzoo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 0.2182,  0.0739, -0.1407,  ..., -0.2717, -0.4562,  0.0300],\n",
      "        [-0.0149, -0.0256,  0.0256,  ..., -0.0156, -0.0337,  0.0693],\n",
      "        [ 0.0961,  0.2174,  0.0590,  ...,  0.0709,  0.0701,  0.1666],\n",
      "        ...,\n",
      "        [ 0.0364,  0.1109,  0.1155,  ...,  0.1096,  0.2287,  0.0670],\n",
      "        [-0.1334, -0.1567, -0.0604,  ..., -0.0971,  0.1199, -0.0038],\n",
      "        [ 0.0959, -0.1972,  0.1799,  ..., -0.0983,  0.1354, -0.3087]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0442, -0.0065, -0.0076,  0.0491, -0.0346,  0.0249, -0.1128,  0.1300],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0519,  0.0733,  0.0460,  ..., -0.1055,  0.0325,  0.0552],\n",
      "        [-0.0064, -0.0206, -0.0599,  ...,  0.0057, -0.2704, -0.0634],\n",
      "        [ 0.0928, -0.0241, -0.0811,  ..., -0.2213, -0.1899,  0.0057],\n",
      "        ...,\n",
      "        [ 0.0316,  0.1695,  0.1535,  ..., -0.0691,  0.0890,  0.0116],\n",
      "        [-0.1191, -0.0340, -0.1168,  ...,  0.0703, -0.0227, -0.1141],\n",
      "        [ 0.2118, -0.0590,  0.1109,  ..., -0.0658, -0.0504,  0.0347]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 1.9864e-02, -2.7307e-02, -3.8380e-03,  1.0930e-02,  1.7056e-02,\n",
      "        -1.0988e-02, -3.1592e-02, -5.6804e-03, -2.7413e-04, -3.2963e-05,\n",
      "        -4.4961e-03,  5.9644e-03,  4.0946e-02,  6.2798e-03, -3.0874e-02,\n",
      "        -2.7076e-02, -5.2212e-03,  9.5728e-03, -1.0870e-02, -6.6869e-03,\n",
      "        -1.0087e-02,  2.5446e-02, -9.3491e-02,  6.8975e-03,  3.9363e-02,\n",
      "         8.9258e-02, -8.1232e-04], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.3288, -0.0625, -0.1979,  ...,  0.0386,  0.2479, -0.2274],\n",
      "        [ 0.3247,  0.0680,  0.1978,  ..., -0.0408, -0.2502,  0.2259]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0770,  0.0770], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0923,  0.0653, -0.1225,  ..., -0.0240,  0.0331,  0.1174],\n",
      "        [ 0.0982,  0.1777, -0.0028,  ...,  0.0942,  0.0647,  0.1164],\n",
      "        [-0.1257, -0.1443, -0.0705,  ...,  0.0358,  0.0811, -0.1707],\n",
      "        [ 0.1284, -0.1037,  0.2031,  ..., -0.1076, -0.1769, -0.0579]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.1731,  0.1246,  0.0396,  0.0066], device='cuda:0',\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.2200,  0.0450,  0.0549,  ...,  0.1398, -0.1435,  0.2764],\n",
      "        [ 0.0547, -0.1299,  0.0278,  ...,  0.1648,  0.2100, -0.1853],\n",
      "        [ 0.1689,  0.0844, -0.0807,  ..., -0.2998, -0.0698, -0.0853]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0459, -0.0946,  0.0513], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1313,  0.0936,  0.0017,  ..., -0.1688, -0.1256, -0.0045],\n",
      "        [-0.1717, -0.1741, -0.0287,  ..., -0.0403,  0.1215,  0.0868],\n",
      "        [ 0.0771,  0.1827,  0.0178,  ...,  0.0169,  0.0192,  0.0622],\n",
      "        ...,\n",
      "        [ 0.0182,  0.0478,  0.1003,  ...,  0.0270,  0.2341,  0.0537],\n",
      "        [ 0.0350,  0.0176,  0.2144,  ...,  0.1477,  0.0426, -0.0141],\n",
      "        [-0.1802,  0.0482, -0.2110,  ...,  0.3299,  0.0218, -0.2423]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0114, -0.0369, -0.0533,  0.0140,  0.1271, -0.0504, -0.0060,  0.0021],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1023, -0.1022,  0.0729,  ...,  0.1531, -0.1189,  0.0977],\n",
      "        [-0.2815, -0.1546,  0.0403,  ..., -0.1742, -0.0360, -0.0510],\n",
      "        [ 0.3834,  0.2572, -0.1132,  ...,  0.0200,  0.1563, -0.0490]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0490,  0.1541, -0.1007], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0242, -0.0115,  0.0714,  ...,  0.1588,  0.0380, -0.1362],\n",
      "        [ 0.0261,  0.0081, -0.0690,  ..., -0.1603, -0.0362,  0.1331]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1017, -0.1037], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3011, -0.1025,  0.0575,  ...,  0.1593, -0.0329, -0.0786],\n",
      "        [-0.2971,  0.1003, -0.0628,  ..., -0.1614,  0.0299,  0.0809]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.2122,  0.2112], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1161,  0.1083,  0.0952,  ...,  0.1515,  0.1135,  0.2288],\n",
      "        [ 0.1136, -0.1064, -0.0941,  ..., -0.1525, -0.1146, -0.2259]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0695, -0.0709], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0295,  0.0315,  0.0388,  ..., -0.1113, -0.1752,  0.0103],\n",
      "        [-0.0288, -0.0332, -0.0424,  ...,  0.1099,  0.1779, -0.0144]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0705, -0.0717], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1457, -0.0237, -0.0161,  ...,  0.2880,  0.1465, -0.1102],\n",
      "        [-0.1413,  0.0238,  0.0128,  ..., -0.2878, -0.1429,  0.1134]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0607, -0.0587], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0706,  0.1161, -0.1261,  ..., -0.2000,  0.2442, -0.1666],\n",
      "        [-0.0685, -0.1187,  0.1223,  ...,  0.2012, -0.2423,  0.1646]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1288, -0.1291], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0350,  0.0536,  0.0940,  ..., -0.1499,  0.1226, -0.0458],\n",
      "        [ 0.0366, -0.0551, -0.0929,  ...,  0.1533, -0.1232,  0.0463]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1122, -0.1085], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1680, -0.1046,  0.1456,  ...,  0.2710, -0.0051, -0.0891],\n",
      "        [ 0.1666,  0.1092, -0.1478,  ..., -0.2696,  0.0011,  0.0836]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0123, -0.0139], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0072,  0.1308, -0.0542,  ..., -0.1115,  0.0431,  0.1326],\n",
      "        [-0.0106, -0.1320,  0.0494,  ...,  0.1111, -0.0387, -0.1356]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1644, -0.1622], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1982, -0.0251, -0.0305,  ...,  0.0083, -0.2624, -0.0789],\n",
      "        [-0.1951,  0.0256,  0.0305,  ..., -0.0073,  0.2636,  0.0822]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1778, -0.1787], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0697, -0.2010, -0.0624,  ...,  0.1255,  0.3204, -0.0375],\n",
      "        [ 0.0729,  0.2014,  0.0608,  ..., -0.1262, -0.3212,  0.0375]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0039,  0.0044], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0151,  0.0866,  0.1968,  ...,  0.2470, -0.0791, -0.0018],\n",
      "        [-0.0144, -0.0824, -0.1951,  ..., -0.2433,  0.0823,  0.0031]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1969, -0.1960], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0622, -0.1224,  0.2596,  ...,  0.3262,  0.2031,  0.1360],\n",
      "        [-0.0585,  0.1246, -0.2621,  ..., -0.3247, -0.2071, -0.1342]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0164, -0.0139], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.1324,  0.0791,  0.0207,  ...,  0.2626, -0.1780, -0.1277],\n",
      "        [-0.1316, -0.0784, -0.0253,  ..., -0.2623,  0.1818,  0.1279]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0707, -0.0727], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1439, -0.0292, -0.1610,  ...,  0.2706,  0.0575, -0.0034],\n",
      "        [ 0.1475,  0.0280,  0.1611,  ..., -0.2733, -0.0514, -0.0014]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0023, -0.0013], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1260,  0.0598,  0.0324,  ...,  0.2418, -0.2786, -0.1872],\n",
      "        [ 0.1273, -0.0598, -0.0336,  ..., -0.2426,  0.2800,  0.1861]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0902, -0.0902], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0491, -0.0265, -0.0120,  ...,  0.0900,  0.2008,  0.1838],\n",
      "        [-0.0545,  0.0307,  0.0121,  ..., -0.0935, -0.1995, -0.1854]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0015, -0.0035], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1358,  0.0469,  0.1602,  ..., -0.0329,  0.0371,  0.1635],\n",
      "        [ 0.1318, -0.0501, -0.1656,  ...,  0.0325, -0.0362, -0.1659]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0096, -0.0070], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0392,  0.0462, -0.0834,  ...,  0.0667, -0.0264,  0.0066],\n",
      "        [-0.0354, -0.0466,  0.0786,  ..., -0.0694,  0.0292, -0.0093]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0202,  0.0222], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "print(params)\n",
    "optimizer = torch.optim.SGD(params, lr=0.001,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 0.0004, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 96.12%, Accuracy2: 109.66%, Accuracy3: 122.28%, Accuracy4: 89.62%, Accuracy5: 108.28%, Accuracy6: 90.81%, Accuracy7: 107.71%, Accuracy8: 115.81%, Accuracy9: 103.00%, Accuracy10: 110.61%, Accuracy11: 122.17%, Accuracy12: 111.45%, Accuracy13: 107.97%, Accuracy14: 112.62%, Accuracy15: 113.71%, Accuracy16: 119.43%, Accuracy17: 109.06%, Accuracy18: 115.76%, Accuracy19: 121.53%, Accuracy20: 118.93%, Accuracy21: 112.92%, Accuracy22: 113.96%, Accuracy23: 119.26%, Accuracy24: 119.10%, Accuracy25: 126.60%, Accuracy26: 126.54%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [2/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [3/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [4/20], Training Loss: 0.0002, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [5/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [6/20], Training Loss: 0.0002, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [7/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [8/20], Training Loss: 0.0004, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [9/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [10/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [11/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [12/20], Training Loss: 0.0003, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [13/20], Training Loss: 0.0004, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [14/20], Training Loss: 0.0002, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n",
      "Epoch [15/20], Training Loss: 0.0004, Validation Loss: 0.7448\n",
      "Training Accuracy : \n",
      "Accuracy1: 91.59%, Accuracy2: 104.87%, Accuracy3: 116.64%, Accuracy4: 85.47%, Accuracy5: 104.48%, Accuracy6: 86.85%, Accuracy7: 103.04%, Accuracy8: 110.65%, Accuracy9: 98.71%, Accuracy10: 106.17%, Accuracy11: 117.05%, Accuracy12: 106.86%, Accuracy13: 102.87%, Accuracy14: 107.86%, Accuracy15: 108.87%, Accuracy16: 114.31%, Accuracy17: 104.06%, Accuracy18: 110.93%, Accuracy19: 116.37%, Accuracy20: 113.84%, Accuracy21: 107.89%, Accuracy22: 109.11%, Accuracy23: 113.72%, Accuracy24: 113.84%, Accuracy25: 121.14%, Accuracy26: 121.06%, \n",
      "Validation Accuracy : \n",
      "Accuracy1: 73.07%, Accuracy2: 83.84%, Accuracy3: 93.20%, Accuracy4: 68.02%, Accuracy5: 83.87%, Accuracy6: 69.54%, Accuracy7: 81.92%, Accuracy8: 88.39%, Accuracy9: 79.06%, Accuracy10: 84.52%, Accuracy11: 93.69%, Accuracy12: 85.39%, Accuracy13: 82.35%, Accuracy14: 86.26%, Accuracy15: 86.63%, Accuracy16: 91.45%, Accuracy17: 83.02%, Accuracy18: 88.39%, Accuracy19: 92.92%, Accuracy20: 91.20%, Accuracy21: 86.19%, Accuracy22: 87.21%, Accuracy23: 90.90%, Accuracy24: 91.12%, Accuracy25: 96.85%, Accuracy26: 96.90%, \n"
     ]
    }
   ],
   "source": [
    "#다중 출력 모델\n",
    "epoch_list = []\n",
    "loss_list = []\n",
    "\n",
    "train_loss_list = []\n",
    "train_accuracy_list = []\n",
    "\n",
    "validation_loss_list = []\n",
    "validation_accuracy_list = []\n",
    "\n",
    "'''\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Total Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "'''\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "\n",
    "        \n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for images, *labels in train_data_loader:  # Use *labels to unpack the list of label tensors\n",
    "        images = images.to(device)\n",
    "        labels = [label.to(device) for label in labels]  # Move each label tensor to the device\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        integer_labels = [torch.argmax(label, dim=1) for label in labels]\n",
    "        \n",
    "        # Calculate loss for each output\n",
    "        losses = [criterion(output, label) for output, label in zip(outputs, integer_labels)]\n",
    "        \n",
    "        # Sum the losses\n",
    "        total_loss = sum(losses)\n",
    "        '''\n",
    "\n",
    "        loss_list.append(total_loss.item()/(len(loss_list)+1))\n",
    "        if len(epoch_list) == 0:\n",
    "            epoch_list.append(1/len(train_data_loader))\n",
    "        else:\n",
    "            epoch_list.append(epoch_list[-1] + 1/len(train_data_loader))\n",
    "            \n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(epoch_list,loss_list, label='Training Loss', color='blue')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.xticks([i for i in range(num_epochs+1)])\n",
    "        plt.yticks([i for i in range(3)])\n",
    "        plt.ylim(0,3)\n",
    "        plt.show()\n",
    "        clear_output(wait=True)\n",
    "        '''\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        \n",
    "        corrects = [torch.sum(torch.argmax(output, 1) == torch.argmax(label, 1)).item() for output, label in zip(outputs, labels)]\n",
    "        total_corrects = [total + correct for total, correct in zip(total_corrects, corrects)]\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_data_loader.dataset)\n",
    "    train_accuracies = [total_correct / len(train_data_loader.dataset) for total_correct in total_corrects]\n",
    "\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_accuracy_list.append(train_accuracies)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_corrects = [0] * len(labels)\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, *labels in validation_data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = [label.to(device) for label in labels]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            integer_labels = [torch.argmax(label, dim=1) for label in labels]\n",
    "\n",
    "            # Calculate loss for each output\n",
    "            losses = [criterion(output, label) for output, label in zip(outputs, integer_labels)]\n",
    "\n",
    "            # Sum the losses\n",
    "            total_loss += sum(losses).item()\n",
    "\n",
    "            # Calculate total correct predictions for each output\n",
    "            corrects = [torch.sum(torch.argmax(output, 1) == torch.argmax(label, 1)).item() for output, label in zip(outputs, labels)]\n",
    "            total_corrects = [total + correct for total, correct in zip(total_corrects, corrects)]\n",
    "\n",
    "    # Calculate average loss and accuracy for each output\n",
    "    avg_validation_loss = total_loss / len(validation_data_loader.dataset)\n",
    "    validation_accuracies = [total_correct / len(validation_data_loader.dataset) for total_correct in total_corrects]\n",
    "\n",
    "    validation_loss_list.append(avg_validation_loss)\n",
    "    validation_accuracy_list.append(validation_accuracies)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_validation_loss:.4f}\")\n",
    "    print(\"Training Accuracy : \")\n",
    "    for i, accuracy in enumerate(train_accuracies):\n",
    "        print(f\"Accuracy{i + 1}: {accuracy * 100:.2f}%, \", end=\"\")\n",
    "    print()\n",
    "    print(\"Validation Accuracy : \")\n",
    "    for i, accuracy in enumerate(validation_accuracies):\n",
    "        print(f\"Accuracy{i + 1}: {accuracy * 100:.2f}%, \", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'multi_output_model_2.pt')\n",
    "torch.save(model.state_dict(), 'multi_output_model_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "              ReLU-2         [-1, 64, 224, 224]               0\n",
      "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
      "              ReLU-4         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
      "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
      "              ReLU-7        [-1, 128, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
      "              ReLU-9        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
      "             ReLU-12          [-1, 256, 56, 56]               0\n",
      "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-14          [-1, 256, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
      "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [-1, 512, 28, 28]               0\n",
      "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [-1, 512, 28, 28]               0\n",
      "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
      "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [-1, 512, 14, 14]               0\n",
      "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [-1, 512, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
      "          Flatten-32                [-1, 25088]               0\n",
      "           Linear-33                    [-1, 8]         200,712\n",
      "           Linear-34                   [-1, 27]         677,403\n",
      "           Linear-35                    [-1, 2]          50,178\n",
      "           Linear-36                    [-1, 4]         100,356\n",
      "           Linear-37                    [-1, 3]          75,267\n",
      "           Linear-38                    [-1, 8]         200,712\n",
      "           Linear-39                    [-1, 3]          75,267\n",
      "           Linear-40                    [-1, 2]          50,178\n",
      "           Linear-41                    [-1, 2]          50,178\n",
      "           Linear-42                    [-1, 2]          50,178\n",
      "           Linear-43                    [-1, 2]          50,178\n",
      "           Linear-44                    [-1, 2]          50,178\n",
      "           Linear-45                    [-1, 2]          50,178\n",
      "           Linear-46                    [-1, 2]          50,178\n",
      "           Linear-47                    [-1, 2]          50,178\n",
      "           Linear-48                    [-1, 2]          50,178\n",
      "           Linear-49                    [-1, 2]          50,178\n",
      "           Linear-50                    [-1, 2]          50,178\n",
      "           Linear-51                    [-1, 2]          50,178\n",
      "           Linear-52                    [-1, 2]          50,178\n",
      "           Linear-53                    [-1, 2]          50,178\n",
      "           Linear-54                    [-1, 2]          50,178\n",
      "           Linear-55                    [-1, 2]          50,178\n",
      "           Linear-56                    [-1, 2]          50,178\n",
      "           Linear-57                    [-1, 2]          50,178\n",
      "           Linear-58                    [-1, 2]          50,178\n",
      "================================================================\n",
      "Total params: 17,047,965\n",
      "Trainable params: 2,333,277\n",
      "Non-trainable params: 14,714,688\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 218.59\n",
      "Params size (MB): 65.03\n",
      "Estimated Total Size (MB): 284.19\n",
      "----------------------------------------------------------------\n",
      "MultiOutputModel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (classifiers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=8, bias=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=27, bias=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=2, bias=True)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4, bias=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=3, bias=True)\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=8, bias=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=3, bias=True)\n",
      "    )\n",
      "    (7-25): 19 x Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 저장한 모델 불러오기\n",
    "\n",
    "from torchsummary import summary\n",
    "model = MultiOutputModel(label_classes)\n",
    "\n",
    "model.load_state_dict(torch.load('multi_output_model_2.pth'))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "summary(model, (3, 224, 224))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'multi_output_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
